// internal/services/analyzer_service.go
package services

import (
	"context"
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"errors"
	"fmt"
	"strings"
	"sync"
	"time"

	"github.com/Corphon/SceneIntruderMCP/internal/llm"
	"github.com/Corphon/SceneIntruderMCP/internal/models"
)

// AnalyzerService åˆ†æå’Œæå–æ–‡æœ¬ä¸­çš„å„ç§ä¿¡æ¯
type AnalyzerService struct {
	LLMService    *LLMService
	semaphore     chan struct{}
	analysisCache *AnalysisCache
}

// åˆ†æç»“æœç¼“å­˜
type AnalysisCache struct {
	cache      map[string]*CachedAnalysis
	mutex      sync.RWMutex
	expiration time.Duration
}

type CachedAnalysis struct {
	Result    *models.AnalysisResult
	Timestamp time.Time
}

// NewAnalyzerService åˆ›å»ºåˆ†ææœåŠ¡
func NewAnalyzerService() (*AnalyzerService, error) {
	llmService, err := NewLLMService()
	if err != nil {
		return nil, err
	}

	return &AnalyzerService{
		LLMService: llmService,
		semaphore:  make(chan struct{}, 3), // é™åˆ¶å¹¶å‘æ•°é‡ä¸º3
		analysisCache: &AnalysisCache{
			cache:      make(map[string]*CachedAnalysis),
			expiration: 30 * time.Minute,
		},
	}, nil
}

// NewAnalyzerServiceWithProvider ä½¿ç”¨æŒ‡å®šçš„LLM Provideråˆ›å»ºåˆ†ææœåŠ¡
func NewAnalyzerServiceWithProvider(provider llm.Provider) *AnalyzerService {
	// æ·»åŠ å¯¹nilæä¾›å•†çš„å¤„ç†
	if provider == nil {
		return &AnalyzerService{
			LLMService: &LLMService{
				provider:     nil,
				providerName: "empty",
				isReady:      false,
				readyState:   "æä¾›å•†æœªåˆå§‹åŒ–",
				cache: &LLMCache{
					cache:      make(map[string]*CacheEntry),
					mutex:      sync.RWMutex{},
					expiration: 30 * time.Minute,
				},
			},
			// ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°é‡
			semaphore: make(chan struct{}, 3),
			analysisCache: &AnalysisCache{
				cache:      make(map[string]*CachedAnalysis),
				expiration: 30 * time.Minute,
			},
		}
	}

	// åŸæœ‰é€»è¾‘ï¼ˆæä¾›å•†ä¸ä¸ºnilæ—¶ï¼‰
	return &AnalyzerService{
		LLMService: &LLMService{
			provider:     provider,
			providerName: provider.GetName(),
			isReady:      true,
			readyState:   "å·²å°±ç»ª",
			cache: &LLMCache{
				cache:      make(map[string]*CacheEntry),
				mutex:      sync.RWMutex{},
				expiration: 30 * time.Minute,
			},
		},
		// ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°é‡
		semaphore: make(chan struct{}, 3),
		analysisCache: &AnalysisCache{
			cache:      make(map[string]*CachedAnalysis),
			expiration: 30 * time.Minute,
		},
	}
}

// AnalyzeText åˆ†ææ–‡æœ¬ï¼Œæå–åœºæ™¯ã€è§’è‰²ã€ç‰©å“ç­‰ä¿¡æ¯
// ğŸ”§ ä¼˜åŒ–åçš„ AnalyzeText æ–¹æ³•
func (s *AnalyzerService) AnalyzeText(text, title string) (*models.AnalysisResult, error) {
	// è·å–å¹¶å‘è®¸å¯
	s.semaphore <- struct{}{}
	defer func() { <-s.semaphore }()

	// æ£€æŸ¥LLMæä¾›å•†æ˜¯å¦å°±ç»ª
	if s.LLMService == nil || !s.LLMService.IsReady() {
		return nil, errors.New("LLMæœåŠ¡æœªé…ç½®æˆ–æœªå°±ç»ªï¼Œè¯·å…ˆåœ¨è®¾ç½®é¡µé¢é…ç½®APIå¯†é’¥")
	}

	// æ£€æŸ¥ç¼“å­˜
	cacheKey := s.generateCacheKey(text, title)
	if cachedResult := s.checkAnalysisCache(cacheKey); cachedResult != nil {
		return cachedResult, nil
	}

	// ä¸€æ¬¡æ€§é¢„å¤„ç†
	isEnglish := isEnglishText(text + " " + title)

	result := &models.AnalysisResult{
		Title: title,
		Metadata: map[string]interface{}{
			"is_english":  isEnglish,
			"text_length": len(text),
		},
	}

	// å¹¶è¡Œæå–ï¼ˆä½¿ç”¨ goroutineï¼‰
	var wg sync.WaitGroup
	var sceneErr, charErr, itemErr, summaryErr error
	var scenes []models.Scene
	var characters []models.Character
	var items []models.Item
	var summary string

	// æå–åœºæ™¯
	wg.Add(1)
	go func() {
		defer wg.Done()
		s, err := s.extractScenes(text, title)
		if err != nil {
			sceneErr = err
			return
		}
		scenes = s
	}()

	// æå–è§’è‰²
	wg.Add(1)
	go func() {
		defer wg.Done()
		characters, err := s.extractCharacters(text, title)
		if err != nil {
			charErr = err
			return
		}
		result.Characters = characters
	}()

	// æå–è§’è‰²
	wg.Add(1)
	go func() {
		defer wg.Done()
		c, err := s.extractCharacters(text, title)
		if err != nil {
			charErr = err
			return
		}
		characters = c
	}()

	// æå–ç‰©å“
	wg.Add(1)
	go func() {
		defer wg.Done()
		i, err := s.extractItems(text, title)
		if err != nil {
			itemErr = err
			return
		}
		items = i
	}()

	// ç”Ÿæˆæ‘˜è¦
	wg.Add(1)
	go func() {
		defer wg.Done()
		sum, err := s.generateSummary(text, title)
		if err != nil {
			summaryErr = err
			return
		}
		summary = sum
	}()

	// ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
	wg.Wait()

	// æ£€æŸ¥é”™è¯¯
	if sceneErr != nil {
		return nil, fmt.Errorf("æå–åœºæ™¯å¤±è´¥: %w", sceneErr)
	}
	if charErr != nil {
		return nil, fmt.Errorf("æå–è§’è‰²å¤±è´¥: %w", charErr)
	}
	if itemErr != nil {
		return nil, fmt.Errorf("æå–ç‰©å“å¤±è´¥: %w", itemErr)
	}
	if summaryErr != nil {
		// æ‘˜è¦ç”Ÿæˆå¤±è´¥ä¸æ˜¯è‡´å‘½é”™è¯¯
		result.Summary = "æ— æ³•ç”Ÿæˆæ‘˜è¦ã€‚"
	}

	// å®‰å…¨åœ°è®¾ç½®ç»“æœ
	result.Scenes = scenes
	result.Characters = characters
	result.Items = items
	result.Summary = summary

	// æ·»åŠ åˆ°ç¼“å­˜
	s.addToAnalysisCache(cacheKey, result)

	return result, nil
}

// æå–åœºæ™¯ä¿¡æ¯
func (s *AnalyzerService) extractScenes(text, title string) ([]models.Scene, error) {
	// ä½¿ç”¨LLMServiceçš„ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½
	sceneInfos, err := s.LLMService.ExtractScenes(context.Background(), text, title)
	if err != nil {
		return nil, err
	}

	// è½¬æ¢ä¸ºæ¨¡å‹æ ¼å¼
	var scenes []models.Scene
	for _, info := range sceneInfos {
		scene := models.Scene{
			Name:        info.Name,
			Description: info.Description,
			Atmosphere:  info.Atmosphere,
			Era:         info.Era,
			Themes:      info.Themes,
		}

		// å¤„ç†ç‰©å“åˆ—è¡¨ - ç¡®ä¿ info.Items æ˜¯å­—ç¬¦ä¸²æ•°ç»„
		var items []models.Item
		if info.Items != nil {
			for _, itemName := range info.Items {
				// ç¡®ä¿ itemName æ˜¯æœ‰æ•ˆå­—ç¬¦ä¸²
				if itemName != "" {
					items = append(items, models.Item{
						Name:        itemName,
						Description: "åœºæ™¯ä¸­çš„ç‰©å“",
					})
				}
			}
		}
		scene.Items = items

		scenes = append(scenes, scene)
	}

	return scenes, nil
}

// æå–è§’è‰²ä¿¡æ¯
func (s *AnalyzerService) extractCharacters(text, title string) ([]models.Character, error) {
	// ä½¿ç”¨LLMServiceçš„ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½
	characterInfos, err := s.LLMService.ExtractCharacters(context.Background(), text, title)
	if err != nil {
		return nil, err
	}

	// è½¬æ¢ä¸ºæ¨¡å‹æ ¼å¼
	var characters []models.Character
	for _, info := range characterInfos {
		character := models.Character{
			Name:        info.Name,
			Role:        info.Role,
			Description: info.Description,
			Personality: info.Personality,
			Background:  info.Background,
			SpeechStyle: info.SpeechStyle,
			Knowledge:   info.Knowledge,
		}

		// å¤„ç†å…³ç³»
		relationships := make(map[string]string)
		for name, relation := range info.Relationships {
			relationships[name] = relation
		}
		character.Relationships = relationships

		characters = append(characters, character)
	}

	return characters, nil
}

// æå–ç‰©å“ä¿¡æ¯
func (s *AnalyzerService) extractItems(text, title string) ([]models.Item, error) {
	type ItemInfo struct {
		Name        string `json:"name"`
		Description string `json:"description"`
		Importance  string `json:"importance"`
		Location    string `json:"location"`
		Usage       string `json:"usage,omitempty"`
	}

	// æ£€æµ‹æ–‡æœ¬è¯­è¨€
	isEnglish := isEnglishText(text + " " + title)

	var prompt, systemPrompt string

	if isEnglish {
		prompt = fmt.Sprintf(`Analyze the following text titled "%s" and extract all important item information:
	
	%s
	
	Please identify all significant items mentioned in the text, providing:
	1. Item name and physical description
	2. Function or purpose within the story
	3. Current location or where it was found
	4. Importance level (critical/important/minor)
	5. Associated characters (who owns/uses it)
	6. Any special properties or abilities
	7. Historical or cultural significance
	
	Focus on items that are plot-relevant, have symbolic meaning, or play a role in character development.`, title, truncateText(text, 5000))

		systemPrompt = `You are a professional item analysis expert specializing in identifying story-relevant objects and artifacts. Extract detailed information about each item's role in the narrative, its symbolic meaning, and practical importance.`
	} else {
		prompt = fmt.Sprintf(`åˆ†æä»¥ä¸‹æ ‡é¢˜ä¸ºã€Š%sã€‹çš„æ–‡æœ¬ï¼Œæå–æ‰€æœ‰é‡è¦ç‰©å“ä¿¡æ¯:
	
	%s
	
	è¯·è¯†åˆ«æ–‡æœ¬ä¸­æåˆ°çš„æ‰€æœ‰é‡è¦ç‰©å“ï¼Œæä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š
	1. ç‰©å“åç§°å’Œå¤–è§‚æè¿°
	2. åœ¨æ•…äº‹ä¸­çš„åŠŸèƒ½æˆ–ç”¨é€”
	3. å½“å‰ä½ç½®æˆ–å‘ç°åœ°ç‚¹
	4. é‡è¦æ€§ç­‰çº§ï¼ˆå…³é”®/é‡è¦/æ¬¡è¦ï¼‰
	5. ç›¸å…³è§’è‰²ï¼ˆè°æ‹¥æœ‰/ä½¿ç”¨å®ƒï¼‰
	6. ä»»ä½•ç‰¹æ®Šå±æ€§æˆ–èƒ½åŠ›
	7. å†å²æˆ–æ–‡åŒ–æ„ä¹‰
	
	é‡ç‚¹å…³æ³¨ä¸æƒ…èŠ‚ç›¸å…³ã€å…·æœ‰è±¡å¾æ„ä¹‰æˆ–åœ¨è§’è‰²å‘å±•ä¸­å‘æŒ¥ä½œç”¨çš„ç‰©å“ã€‚`, title, truncateText(text, 5000))

		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç‰©å“åˆ†æä¸“å®¶ï¼Œä¸“é—¨è¯†åˆ«æ•…äº‹ç›¸å…³çš„ç‰©ä½“å’Œæ–‡ç‰©ã€‚æå–æ¯ä¸ªç‰©å“åœ¨å™äº‹ä¸­çš„ä½œç”¨ã€è±¡å¾æ„ä¹‰å’Œå®é™…é‡è¦æ€§çš„è¯¦ç»†ä¿¡æ¯ã€‚`
	}

	// ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºAPIè·å–å“åº”
	request := llm.CompletionRequest{
		Model:        s.LLMService.GetDefaultModel(),
		Prompt:       prompt,
		SystemPrompt: systemPrompt,
		MaxTokens:    2000,
		Temperature:  0.2,
	}

	// å°è¯•ä»ç¼“å­˜è·å–
	cacheKey := s.LLMService.GenerateCacheKey(request)
	var response *llm.CompletionResponse
	if cachedResp := s.LLMService.CheckCache(cacheKey); cachedResp != nil {
		response = cachedResp
	} else {
		// æ‰§è¡ŒAPIè°ƒç”¨
		var err error
		response, err = s.LLMService.provider.CompleteText(context.Background(), request)
		if err != nil {
			return nil, err
		}
		// æ·»åŠ åˆ°ç¼“å­˜
		s.LLMService.AddToCache(cacheKey, response)
	}
	// å°è¯•è§£æä¸ºæ•°ç»„æ ¼å¼
	var itemInfos []ItemInfo
	err := json.Unmarshal([]byte(response.Text), &itemInfos)
	if err == nil {
		// æ•°ç»„è§£ææˆåŠŸ
		var items []models.Item
		for _, info := range itemInfos {
			item := models.Item{
				Name:        info.Name,
				Description: info.Description,
				Location:    info.Location,
			}
			items = append(items, item)
		}
		return items, nil
	}

	// å¦‚æœè§£ææ•°ç»„å¤±è´¥ï¼Œå°è¯•è§£æä¸ºå•ä¸ªå¯¹è±¡
	var singleItem ItemInfo
	err = json.Unmarshal([]byte(response.Text), &singleItem)
	if err != nil {
		return nil, fmt.Errorf("è§£æAIå“åº”ä¸ºç»“æ„åŒ–æ•°æ®å¤±è´¥: %w\nAIè¿”å›: %s",
			err, truncateText(response.Text, 120))
	}

	// å°†å•ä¸ªå¯¹è±¡æ·»åŠ åˆ°æ•°ç»„ä¸­
	return []models.Item{
		{
			Name:        singleItem.Name,
			Description: singleItem.Description,
			Location:    singleItem.Location,
		},
	}, nil
}

// ç”Ÿæˆæ•…äº‹æ‘˜è¦
func (s *AnalyzerService) generateSummary(text, title string) (string, error) {
	type SummaryResponse struct {
		Summary string `json:"summary"`
	}

	var response SummaryResponse

	// æ£€æµ‹æ–‡æœ¬è¯­è¨€
	isEnglish := isEnglishText(text + " " + title)

	var prompt, systemPrompt string

	if isEnglish {
		// è‹±æ–‡æç¤ºè¯
		prompt = fmt.Sprintf(`Create a concise summary for the following text titled "%s":

%s

The summary should be brief and capture the main plot, characters, and themes of the story.`, title, truncateText(text, 5000))

		systemPrompt = `You are a professional literary summary expert, skilled at creating concise yet comprehensive summaries for stories.`
	} else {
		// ä¸­æ–‡æç¤ºè¯ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
		prompt = fmt.Sprintf(`ä¸ºä»¥ä¸‹æ ‡é¢˜ä¸ºã€Š%sã€‹çš„æ–‡æœ¬åˆ›å»ºä¸€ä¸ªç®€æ´çš„æ‘˜è¦:

%s

æ‘˜è¦åº”è¯¥ç®€æ˜æ‰¼è¦ï¼Œæ•æ‰æ•…äº‹çš„ä¸»è¦æƒ…èŠ‚ã€è§’è‰²å’Œä¸»é¢˜ã€‚`, title, truncateText(text, 5000))

		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡å­¦æ‘˜è¦ä¸“å®¶ï¼Œæ“…é•¿ä¸ºæ•…äº‹åˆ›å»ºç®€æ˜è€Œå…¨é¢çš„æ‘˜è¦ã€‚`
	}

	err := s.LLMService.CreateStructuredCompletion(context.Background(), prompt, systemPrompt, &response)
	if err != nil {
		return "", err
	}

	return response.Summary, nil
}

// è¾…åŠ©å‡½æ•°ï¼Œä¿æŒæ–‡æœ¬é•¿åº¦åœ¨é™åˆ¶èŒƒå›´å†…
func truncateText(text string, maxLength int) string {
	// å¤„ç†è¾¹ç•Œæƒ…å†µ
	if maxLength <= 0 {
		return "..."
	}

	if len(text) == 0 {
		return ""
	}

	// å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºç¬¦æ–‡(rune)æ•°ç»„ï¼Œä»¥æ­£ç¡®å¤„ç†ä¸­æ–‡ç­‰å¤šå­—èŠ‚å­—ç¬¦
	runes := []rune(text)
	if len(runes) <= maxLength {
		return text
	}

	// ç¡®ä¿æˆªæ–­é•¿åº¦ä¸ä¼šè¶…å‡ºèŒƒå›´
	if maxLength > len(runes) {
		maxLength = len(runes)
	}

	// æˆªå–æŒ‡å®šé•¿åº¦çš„ç¬¦æ–‡ï¼Œç„¶åæ·»åŠ çœç•¥å·
	return string(runes[:maxLength]) + "..."
}

// AnalyzeTextWithProgress å¸¦è¿›åº¦åé¦ˆå’Œè¶…æ—¶æ§åˆ¶çš„æ–‡æœ¬åˆ†æ
func (s *AnalyzerService) AnalyzeTextWithProgress(ctx context.Context, text string, tracker *ProgressTracker) (*models.AnalysisResult, error) {
	// è·å–å¹¶å‘è®¸å¯
	s.semaphore <- struct{}{}
	defer func() { <-s.semaphore }()

	// æ£€æŸ¥contextæ˜¯å¦å·²ç»å–æ¶ˆ
	if ctx.Err() != nil {
		return nil, ctx.Err()
	}

	// ä½¿ç”¨å­contextå’Œtimeout
	analyzeCtx, cancel := context.WithTimeout(ctx, 3*time.Minute)
	defer cancel()

	result := &models.AnalysisResult{
		Title:      "åˆ†æä¸­...",
		Characters: make([]models.Character, 0), // ä¸AnalyzeTextå‡½æ•°ä¿æŒä¸€è‡´çš„ç±»å‹
		Scenes:     []models.Scene{},            // ä½¿ç”¨æ­£ç¡®çš„å­—æ®µåç§°
		Items:      []models.Item{},
	}

	// æ­¥éª¤1: åˆæ­¥æ–‡æœ¬åˆ†æ (10%)
	tracker.UpdateProgress(10, "åˆæ­¥åˆ†ææ–‡æœ¬å†…å®¹...")
	if err := s.preliminaryAnalysis(analyzeCtx, text, result); err != nil {
		return nil, fmt.Errorf("åˆæ­¥æ–‡æœ¬åˆ†æå¤±è´¥: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
	if analyzeCtx.Err() != nil {
		return nil, analyzeCtx.Err()
	}

	// æ­¥éª¤2: æå–åœºæ™¯ä¿¡æ¯ (30%)
	tracker.UpdateProgress(30, "æå–åœºæ™¯ä¿¡æ¯...")
	if err := s.extractSceneInfo(analyzeCtx, text, result); err != nil {
		return nil, fmt.Errorf("æå–åœºæ™¯ä¿¡æ¯å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
	if analyzeCtx.Err() != nil {
		return nil, analyzeCtx.Err()
	}

	// æ­¥éª¤3: è§’è‰²è¯†åˆ«ä¸åˆ†æ (60%)
	tracker.UpdateProgress(60, "è¯†åˆ«å’Œåˆ†æè§’è‰²...")
	if err := s.extractCharacterInfo(analyzeCtx, text, result); err != nil {
		return nil, fmt.Errorf("è§’è‰²åˆ†æå¤±è´¥: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
	if analyzeCtx.Err() != nil {
		return nil, analyzeCtx.Err()
	}

	// æ­¥éª¤4: æ„å»ºè§’è‰²å…³ç³» (80%)
	tracker.UpdateProgress(80, "æ„å»ºè§’è‰²å…³ç³»ç½‘ç»œ...")
	if err := s.buildCharacterRelationships(analyzeCtx, result.Characters); err != nil {
		return nil, fmt.Errorf("æ„å»ºè§’è‰²å…³ç³»å¤±è´¥: %w", err)
	}

	// æ­¥éª¤5: å®Œæˆåˆ†æ (95%)
	tracker.UpdateProgress(95, "å®Œæˆåˆ†æï¼Œå‡†å¤‡ç»“æœ...")

	// æ‰§è¡Œæœ€ç»ˆå¤„ç†...

	// ä»»åŠ¡å®Œæˆ
	tracker.Complete("åˆ†ææˆåŠŸå®Œæˆ")

	return result, nil
}

// preliminaryAnalysis æ‰§è¡Œæ–‡æœ¬çš„åˆæ­¥åˆ†æï¼Œè®¾ç½®åŸºæœ¬å±æ€§
func (s *AnalyzerService) preliminaryAnalysis(ctx context.Context, text string, result *models.AnalysisResult) error {
	// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
		// ç»§ç»­æ‰§è¡Œ
	}

	// åˆ†ææ–‡æœ¬é•¿åº¦å’Œå¤æ‚åº¦
	textLength := len(text)
	result.TextLength = textLength

	// è®¾ç½®åˆæ­¥æ ‡é¢˜ï¼ˆå¦‚æœä¸ºç©ºï¼‰
	if result.Title == "åˆ†æä¸­..." && textLength > 0 {
		// æˆªå–å‰30ä¸ªå­—ç¬¦ä½œä¸ºä¸´æ—¶æ ‡é¢˜åŸºç¡€
		titleBase := text
		if len(text) > 30 {
			titleBase = text[:30]
		}

		// æ ¹æ®æ–‡æœ¬è¯­è¨€è®¾ç½®ä¸åŒçš„æ ‡é¢˜æ ¼å¼
		if isEnglishText(titleBase) {
			result.Title = "Analysis of \"" + strings.TrimSpace(titleBase) + "...\""
		} else {
			result.Title = "ã€Š" + strings.TrimSpace(titleBase) + "...ã€‹çš„åˆ†æ"
		}
	}

	// æ£€æµ‹æ–‡æœ¬è¯­è¨€
	isEnglish := isEnglishText(text)

	// æ‰©å±•ç±»å‹åˆ†æç»“æ„ï¼Œå¢åŠ æ›´å¤šä¿¡æ¯
	type EnhancedTypeAnalysis struct {
		Type             string   `json:"type"`              // æ–‡æœ¬ç±»å‹
		Themes           []string `json:"themes"`            // ä¸»è¦ä¸»é¢˜
		GenreAttributes  []string `json:"genre_attributes"`  // ä½“è£ç‰¹æ€§
		Mood             string   `json:"mood"`              // æ•´ä½“æƒ…æ„ŸåŸºè°ƒ
		WritingStyle     string   `json:"writing_style"`     // å†™ä½œé£æ ¼
		TargetAudience   string   `json:"target_audience"`   // ç›®æ ‡å—ä¼—
		EstimatedEra     string   `json:"estimated_era"`     // ä¼°è®¡åˆ›ä½œå¹´ä»£/æ—¶æœŸ
		KeyElements      []string `json:"key_elements"`      // å…³é”®å…ƒç´ 
		LanguageFeatures string   `json:"language_features"` // è¯­è¨€ç‰¹ç‚¹
	}

	var typeInfo EnhancedTypeAnalysis
	// ä½¿ç”¨è¾ƒçŸ­çš„è¶…æ—¶ï¼Œå› ä¸ºè¿™åªæ˜¯åˆæ­¥åˆ†æ
	typeCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
	defer cancel()

	var textTypePrompt, systemPrompt string

	if isEnglish {
		textTypePrompt = fmt.Sprintf(`Conduct a comprehensive literary analysis of the following text excerpt:
	
	%s
	
	Provide detailed analysis including:
	1. **Text Type**: Specific genre classification (e.g., "gothic novel excerpt", "science fiction short story", "historical drama", "contemporary romance")
	2. **Primary Themes**: Core thematic elements and their significance
	3. **Genre Attributes**: Distinctive features that define the genre
	4. **Mood/Tone**: Emotional atmosphere and authorial attitude
	5. **Writing Style**: Narrative techniques, prose style, and literary devices
	6. **Target Audience**: Intended readership demographics and interests
	7. **Estimated Era**: Historical period of writing or setting, with reasoning
	8. **Key Elements**: Notable plot devices, character archetypes, or structural features
	9. **Language Features**: Distinctive vocabulary, syntax, or stylistic choices
	
	Provide specific examples from the text to support your analysis.`, truncateText(text, 1000))

		systemPrompt = `You are a distinguished literary scholar with expertise in genre analysis, stylistic criticism, and textual interpretation. Your analysis should be academically rigorous yet accessible, providing specific textual evidence for your conclusions.`
	} else {
		textTypePrompt = fmt.Sprintf(`å¯¹ä»¥ä¸‹æ–‡æœ¬ç‰‡æ®µè¿›è¡Œå…¨é¢çš„æ–‡å­¦åˆ†æ:
	
	%s
	
	è¯·æä¾›è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬ï¼š
	1. **æ–‡æœ¬ç±»å‹**ï¼šå…·ä½“çš„ä½“è£åˆ†ç±»ï¼ˆå¦‚"å“¥ç‰¹å¼å°è¯´ç‰‡æ®µ"ã€"ç§‘å¹»çŸ­ç¯‡å°è¯´"ã€"å†å²å‰§æœ¬"ã€"å½“ä»£è¨€æƒ…å°è¯´"ï¼‰
	2. **ä¸»è¦ä¸»é¢˜**ï¼šæ ¸å¿ƒä¸»é¢˜å…ƒç´ åŠå…¶æ„ä¹‰
	3. **ä½“è£ç‰¹æ€§**ï¼šå®šä¹‰è¯¥ä½“è£çš„ç‹¬ç‰¹ç‰¹å¾
	4. **æƒ…æ„ŸåŸºè°ƒ**ï¼šæƒ…æ„Ÿæ°›å›´å’Œä½œè€…æ€åº¦
	5. **å†™ä½œé£æ ¼**ï¼šå™äº‹æŠ€å·§ã€æ•£æ–‡é£æ ¼å’Œæ–‡å­¦æ‰‹æ³•
	6. **ç›®æ ‡å—ä¼—**ï¼šé¢„æœŸè¯»è€…ç¾¤ä½“å’Œå…´è¶£åå¥½
	7. **ä¼°è®¡å¹´ä»£**ï¼šå†™ä½œæˆ–èƒŒæ™¯çš„å†å²æ—¶æœŸï¼Œå¹¶è¯´æ˜ç†ç”±
	8. **å…³é”®å…ƒç´ **ï¼šå€¼å¾—æ³¨æ„çš„æƒ…èŠ‚è®¾è®¡ã€è§’è‰²åŸå‹æˆ–ç»“æ„ç‰¹å¾
	9. **è¯­è¨€ç‰¹ç‚¹**ï¼šç‹¬ç‰¹çš„è¯æ±‡ã€å¥æ³•æˆ–é£æ ¼é€‰æ‹©
	
	è¯·ä»æ–‡æœ¬ä¸­æä¾›å…·ä½“ä¾‹è¯æ¥æ”¯æŒæ‚¨çš„åˆ†æã€‚`, truncateText(text, 1000))

		systemPrompt = `ä½ æ˜¯ä¸€ä½æ°å‡ºçš„æ–‡å­¦å­¦è€…ï¼Œåœ¨ä½“è£åˆ†æã€é£æ ¼æ‰¹è¯„å’Œæ–‡æœ¬è§£è¯»æ–¹é¢å…·æœ‰ä¸“ä¸šçŸ¥è¯†ã€‚ä½ çš„åˆ†æåº”è¯¥æ—¢å…·æœ‰å­¦æœ¯ä¸¥è°¨æ€§åˆé€šä¿—æ˜“æ‡‚ï¼Œä¸ºä½ çš„ç»“è®ºæä¾›å…·ä½“çš„æ–‡æœ¬è¯æ®ã€‚`
	}

	err := s.LLMService.CreateStructuredCompletion(
		typeCtx,
		textTypePrompt,
		systemPrompt,
		&typeInfo,
	)

	if err != nil {
		// åˆæ­¥åˆ†æå¤±è´¥ä¸æ˜¯è‡´å‘½é”™è¯¯ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­
		fmt.Printf("æ–‡æœ¬ç±»å‹è¯†åˆ«å¤±è´¥: %v\n", err)
	} else {
		// è®¾ç½®æ–‡æœ¬ç±»å‹å’Œä¸»é¢˜
		result.TextType = typeInfo.Type
		result.Themes = typeInfo.Themes

		// æ‰©å±•ç»“æœå¯¹è±¡ä»¥å­˜å‚¨æ›´å¤šåˆ†ææ•°æ®
		if result.Metadata == nil {
			result.Metadata = make(map[string]interface{})
		}

		// å­˜å‚¨å¢å¼ºçš„åˆ†æç»“æœ
		result.Metadata["genre_attributes"] = typeInfo.GenreAttributes
		result.Metadata["mood"] = typeInfo.Mood
		result.Metadata["writing_style"] = typeInfo.WritingStyle
		result.Metadata["target_audience"] = typeInfo.TargetAudience
		result.Metadata["estimated_era"] = typeInfo.EstimatedEra
		result.Metadata["key_elements"] = typeInfo.KeyElements
		result.Metadata["language_features"] = typeInfo.LanguageFeatures
	}

	// æ·»åŠ è¯­è¨€æ£€æµ‹ç»“æœ
	result.Metadata["is_english"] = isEnglish

	// è¿›è¡Œç®€å•æƒ…æ„Ÿåˆ†æï¼Œç¡®å®šæ–‡æœ¬çš„ä¸»è¦æƒ…æ„Ÿè‰²å½©
	// è¿™å¯ä»¥ä½œä¸ºå•ç‹¬å‡½æ•°æˆ–é›†æˆåˆ°ä¸Šè¿°åˆ†æä¸­
	if len(text) > 0 && typeInfo.Mood == "" {
		moodCtx, moodCancel := context.WithTimeout(ctx, 15*time.Second)
		defer moodCancel()

		type MoodAnalysis struct {
			PrimaryMood    string   `json:"primary_mood"`
			SecondaryMoods []string `json:"secondary_moods"`
			EmotionalTone  string   `json:"emotional_tone"`
		}

		var moodInfo MoodAnalysis
		var moodPrompt string

		if isEnglish {
			moodPrompt = fmt.Sprintf(`Analyze the emotional tone and mood of the following text:

%s

Identify the primary mood, any secondary moods, and overall emotional tone.`, truncateText(text, 800))
		} else {
			moodPrompt = fmt.Sprintf(`åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„ŸåŸºè°ƒå’Œæ°›å›´:

%s

è¯†åˆ«ä¸»è¦æƒ…æ„Ÿæ°›å›´ã€æ¬¡è¦æƒ…æ„Ÿä»¥åŠæ•´ä½“æƒ…æ„ŸåŸºè°ƒã€‚`, truncateText(text, 800))
		}

		// ä½¿ç”¨çŸ­è¶…æ—¶è¿›è¡Œæƒ…æ„Ÿåˆ†æ
		if err := s.LLMService.CreateStructuredCompletion(
			moodCtx,
			moodPrompt,
			systemPrompt,
			&moodInfo,
		); err == nil {
			// å­˜å‚¨æƒ…æ„Ÿåˆ†æç»“æœ
			result.Metadata["primary_mood"] = moodInfo.PrimaryMood
			result.Metadata["secondary_moods"] = moodInfo.SecondaryMoods
			result.Metadata["emotional_tone"] = moodInfo.EmotionalTone
		}
	}

	// å¦‚æœæ–‡æœ¬è¾ƒé•¿ï¼Œå°è¯•æå–é‡è¦äººåå’Œåœ°ç‚¹
	if len(text) > 1000 {
		namesCtx, namesCancel := context.WithTimeout(ctx, 15*time.Second)
		defer namesCancel()

		type NamedEntities struct {
			Characters []string `json:"characters"`
			Locations  []string `json:"locations"`
			TimeFrames []string `json:"time_frames"`
		}

		var entities NamedEntities
		var entitiesPrompt string

		if isEnglish {
			entitiesPrompt = fmt.Sprintf(`Extract key named entities from the following text:

%s

List main character names, locations, and any time frames or periods mentioned.`, truncateText(text, 800))
		} else {
			entitiesPrompt = fmt.Sprintf(`ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®å‘½åå®ä½“:

%s

åˆ—å‡ºä¸»è¦è§’è‰²åç§°ã€åœ°ç‚¹ä»¥åŠæåˆ°çš„ä»»ä½•æ—¶é—´æ¡†æ¶æˆ–æ—¶æœŸã€‚`, truncateText(text, 800))
		}

		// å®ä½“æå–
		if err := s.LLMService.CreateStructuredCompletion(
			namesCtx,
			entitiesPrompt,
			systemPrompt,
			&entities,
		); err == nil {
			// å­˜å‚¨å®ä½“æå–ç»“æœ
			result.Metadata["preliminary_characters"] = entities.Characters
			result.Metadata["preliminary_locations"] = entities.Locations
			result.Metadata["time_frames"] = entities.TimeFrames
		}
	}

	return nil
}

// extractSceneInfo æå–åœºæ™¯ä¿¡æ¯ï¼Œæ”¯æŒä¸Šä¸‹æ–‡æ§åˆ¶å’Œè¿›åº¦åé¦ˆ
func (s *AnalyzerService) extractSceneInfo(ctx context.Context, text string, result *models.AnalysisResult) error {
	// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
		// ç»§ç»­æ‰§è¡Œ
	}

	// ä½¿ç”¨ç°æœ‰çš„åœºæ™¯æå–åŠŸèƒ½ï¼Œä½†ä¼ å…¥ä¸Šä¸‹æ–‡
	sceneInfos, err := s.LLMService.ExtractScenes(ctx, text, result.Title)
	if err != nil {
		return err
	}

	// è½¬æ¢ä¸ºæ¨¡å‹æ ¼å¼
	var scenes []models.Scene
	for _, info := range sceneInfos {
		scene := models.Scene{
			Name:        info.Name,
			Description: info.Description,
			Atmosphere:  info.Atmosphere,
			Era:         info.Era,    // ç¡®ä¿åŒ…å«æ—¶ä»£ä¿¡æ¯
			Themes:      info.Themes, // ç¡®ä¿åŒ…å«ä¸»é¢˜ä¿¡æ¯
		}

		// å¤„ç†ç‰©å“åˆ—è¡¨
		var items []models.Item
		if info.Items != nil {
			for _, itemName := range info.Items {
				if itemName != "" {
					items = append(items, models.Item{
						Name:        itemName,
						Description: "åœºæ™¯ä¸­çš„ç‰©å“",
					})
				}
			}
		}
		scene.Items = items

		scenes = append(scenes, scene)
	}

	// æ›´æ–°ç»“æœå¯¹è±¡
	result.Scenes = scenes

	// å¦‚æœæœ‰åœºæ™¯ï¼Œæ›´æ–°æ ‡é¢˜
	if len(scenes) > 0 && result.Title == "åˆ†æä¸­..." {
		result.Title = scenes[0].Name
	}

	return nil
}

// extractCharacterInfo æå–è§’è‰²ä¿¡æ¯ï¼Œæ”¯æŒä¸Šä¸‹æ–‡æ§åˆ¶å’Œè¿›åº¦åé¦ˆ
func (s *AnalyzerService) extractCharacterInfo(ctx context.Context, text string, result *models.AnalysisResult) error {
	// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
		// ç»§ç»­æ‰§è¡Œ
	}

	// ä½¿ç”¨LLMServiceçš„ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½ï¼Œä½†ä¼ å…¥ä¸Šä¸‹æ–‡
	characterInfos, err := s.LLMService.ExtractCharacters(ctx, text, result.Title)
	if err != nil {
		return err
	}

	// è½¬æ¢ä¸ºæ¨¡å‹æ ¼å¼
	var characters []models.Character
	for _, info := range characterInfos {
		character := models.Character{
			Name:        info.Name,
			Role:        info.Role,
			Description: info.Description,
			Personality: info.Personality,
			Background:  info.Background,
			SpeechStyle: info.SpeechStyle,
			Knowledge:   info.Knowledge,
		}

		// å¤„ç†å…³ç³»
		relationships := make(map[string]string)
		for name, relation := range info.Relationships {
			relationships[name] = relation
		}
		character.Relationships = relationships

		characters = append(characters, character)
	}

	// ä¿å­˜åˆ°ç»“æœå¯¹è±¡
	result.Characters = characters

	return nil
}

// buildCharacterRelationships æ„å»ºå’Œå¢å¼ºè§’è‰²ä¹‹é—´çš„å…³ç³»ç½‘ç»œ
func (s *AnalyzerService) buildCharacterRelationships(ctx context.Context, characters []models.Character) error {
	// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
		// ç»§ç»­æ‰§è¡Œ
	}

	// å¦‚æœè§’è‰²å¤ªå°‘ï¼Œä¸éœ€è¦é¢å¤–å¤„ç†
	if len(characters) <= 1 {
		return nil
	}

	// å‡†å¤‡è§’è‰²å…³ç³»ç½‘ç»œåˆ†æçš„è¾“å…¥æ•°æ®
	type RelationshipInput struct {
		Name        string            `json:"name"`
		Role        string            `json:"role"`
		Description string            `json:"description,omitempty"`
		Relations   map[string]string `json:"relations"`
	}

	inputs := make([]RelationshipInput, len(characters))
	for i, char := range characters {
		inputs[i] = RelationshipInput{
			Name:        char.Name,
			Role:        char.Role,
			Description: char.Description,
			Relations:   char.Relationships,
		}
	}

	// åˆ›å»ºå…³ç³»ç½‘ç»œåˆ†æçš„è¯·æ±‚
	type RelationshipOutput struct {
		Characters []struct {
			Name      string            `json:"name"`
			Relations map[string]string `json:"relations"`
		} `json:"characters"`
	}

	// å‡†å¤‡æç¤ºè¯
	inputJSON, _ := json.Marshal(inputs)

	// æ£€æµ‹è¾“å…¥è¯­è¨€ï¼ˆåŸºäºè§’è‰²åç§°å’Œæè¿°ï¼‰
	var textSample strings.Builder
	for _, char := range characters {
		textSample.WriteString(char.Name + " " + char.Description + " ")
	}
	isEnglish := isEnglishText(textSample.String())

	var prompt, systemPrompt string

	if isEnglish {
		prompt = fmt.Sprintf(`Analyze the following character information and enhance the relationship network:
	
	%s
	
	Please ensure comprehensive relationship mapping with the following requirements:
	1. **Bidirectional Consistency**: If A is B's father, then B should be A's child
	2. **Relationship Depth**: Specify the nature and quality of relationships (close/distant, positive/negative/neutral)
	3. **Inferred Relationships**: Based on character descriptions, infer logical relationships between characters who haven't directly interacted
	4. **Relationship Evolution**: Consider how relationships might change throughout the story
	5. **Power Dynamics**: Identify hierarchical relationships and social positions
	6. **Emotional Bonds**: Distinguish between formal relationships and emotional connections
	7. **Conflict Relationships**: Identify antagonistic or competitive relationships
	
	For each character, provide their relationship with ALL other characters, even if it's "stranger" or "no direct relationship".`, string(inputJSON))

		systemPrompt = `You are an expert in character relationship analysis and social network mapping for literature. Your analysis should create a comprehensive, psychologically realistic relationship matrix that enhances story understanding and character development potential.`
	} else {
		prompt = fmt.Sprintf(`åˆ†æä»¥ä¸‹è§’è‰²ä¿¡æ¯ï¼Œå®Œå–„è§’è‰²ä¹‹é—´çš„å…³ç³»ç½‘ç»œ:
	
	%s
	
	è¯·ç¡®ä¿å…¨é¢çš„å…³ç³»æ˜ å°„ï¼Œæ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š
	1. **åŒå‘ä¸€è‡´æ€§**ï¼šå¦‚æœAæ˜¯Bçš„çˆ¶äº²ï¼Œé‚£ä¹ˆBåº”è¯¥æ˜¯Açš„å­©å­
	2. **å…³ç³»æ·±åº¦**ï¼šæŒ‡æ˜å…³ç³»çš„æ€§è´¨å’Œè´¨é‡ï¼ˆäº²å¯†/ç–è¿œï¼Œæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰
	3. **æ¨æ–­å…³ç³»**ï¼šåŸºäºè§’è‰²æè¿°ï¼Œæ¨æ–­æ²¡æœ‰ç›´æ¥äº’åŠ¨çš„è§’è‰²ä¹‹é—´çš„é€»è¾‘å…³ç³»
	4. **å…³ç³»æ¼”å˜**ï¼šè€ƒè™‘å…³ç³»åœ¨æ•…äº‹ä¸­å¯èƒ½çš„å˜åŒ–
	5. **æƒåŠ›åŠ¨æ€**ï¼šè¯†åˆ«ç­‰çº§å…³ç³»å’Œç¤¾ä¼šåœ°ä½
	6. **æƒ…æ„Ÿçº½å¸¦**ï¼šåŒºåˆ†æ­£å¼å…³ç³»å’Œæƒ…æ„Ÿè”ç³»
	7. **å†²çªå…³ç³»**ï¼šè¯†åˆ«å¯¹æŠ—æ€§æˆ–ç«äº‰æ€§å…³ç³»
	
	å¯¹äºæ¯ä¸ªè§’è‰²ï¼Œæä¾›ä»–ä»¬ä¸æ‰€æœ‰å…¶ä»–è§’è‰²çš„å…³ç³»ï¼Œå³ä½¿æ˜¯"é™Œç”Ÿäºº"æˆ–"æ— ç›´æ¥å…³ç³»"ã€‚`, string(inputJSON))

		systemPrompt = `ä½ æ˜¯æ–‡å­¦ä¸­è§’è‰²å…³ç³»åˆ†æå’Œç¤¾äº¤ç½‘ç»œæ˜ å°„çš„ä¸“å®¶ã€‚ä½ çš„åˆ†æåº”è¯¥åˆ›å»ºä¸€ä¸ªå…¨é¢çš„ã€å¿ƒç†å­¦ä¸Šç°å®çš„å…³ç³»çŸ©é˜µï¼Œå¢å¼ºæ•…äº‹ç†è§£å’Œè§’è‰²å‘å±•æ½œåŠ›ã€‚`
	}
	var output RelationshipOutput
	if err := s.LLMService.CreateStructuredCompletion(ctx, prompt, systemPrompt, &output); err != nil {
		return fmt.Errorf("åˆ†æè§’è‰²å…³ç³»å¤±è´¥: %w", err)
	}

	// æ›´æ–°è§’è‰²å…³ç³»
	for i := range characters {
		for _, enhancedChar := range output.Characters {
			if characters[i].Name == enhancedChar.Name {
				// åªæ›´æ–°å…³ç³»ï¼Œä¿æŒå…¶ä»–å­—æ®µä¸å˜
				if len(enhancedChar.Relations) > 0 {
					characters[i].Relationships = enhancedChar.Relations
				}
				break
			}
		}
	}

	return nil
}

// ğŸ”§ ç”Ÿæˆç¼“å­˜é”®
func (s *AnalyzerService) generateCacheKey(text, title string) string {
	h := md5.New()
	h.Write([]byte(text + "|" + title))
	return hex.EncodeToString(h.Sum(nil))
}

// ğŸ”§ æ£€æŸ¥ç¼“å­˜
func (s *AnalyzerService) checkAnalysisCache(cacheKey string) *models.AnalysisResult {
	s.analysisCache.mutex.RLock()
	defer s.analysisCache.mutex.RUnlock()

	if cached, exists := s.analysisCache.cache[cacheKey]; exists {
		if time.Since(cached.Timestamp) < s.analysisCache.expiration {
			return cached.Result
		}
		// è¿‡æœŸï¼Œåˆ é™¤
		delete(s.analysisCache.cache, cacheKey)
	}

	return nil
}

// ğŸ”§ æ·»åŠ åˆ°ç¼“å­˜
func (s *AnalyzerService) addToAnalysisCache(cacheKey string, result *models.AnalysisResult) {
	s.analysisCache.mutex.Lock()
	defer s.analysisCache.mutex.Unlock()

	s.analysisCache.cache[cacheKey] = &CachedAnalysis{
		Result:    result,
		Timestamp: time.Now(),
	}
}
