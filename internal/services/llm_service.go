// internal/services/llm_service.go
package services

import (
	"context"
	"crypto/md5"
	"encoding/json"
	"fmt"
	"log"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/Corphon/SceneIntruderMCP/internal/config"
	"github.com/Corphon/SceneIntruderMCP/internal/llm"
)

const (
	RoleSystem    = "system"
	RoleUser      = "user"
	RoleAssistant = "assistant"
)

// LLMService æä¾›ç»Ÿä¸€çš„å¤§è¯­è¨€æ¨¡å‹è°ƒç”¨æ¥å£
type LLMService struct {
	providerMutex sync.RWMutex
	provider      llm.Provider
	providerName  string
	cache         *LLMCache
	isReady       bool
	readyState    string
}
type LLMCache struct {
	cache      map[string]*CacheEntry
	mutex      sync.RWMutex
	expiration time.Duration
}

type CacheEntry struct {
	Response  interface{}
	CreatedAt time.Time
}

// ChatCompletionRequest å…¼å®¹æ—§çš„è¯·æ±‚æ ¼å¼
type ChatCompletionRequest struct {
	Model       string                  `json:"model"`
	Messages    []ChatCompletionMessage `json:"messages"`
	Temperature float64                 `json:"temperature"`
	MaxTokens   int                     `json:"max_tokens"`
	ExtraParams map[string]interface{}  `json:"extra_params,omitempty"`
}

// ChatCompletionMessage å…¼å®¹æ—§çš„æ¶ˆæ¯æ ¼å¼
type ChatCompletionMessage struct {
	Role    string
	Content string
}

// ChatCompletionResponse å…¼å®¹æ—§çš„å“åº”æ ¼å¼
type ChatCompletionResponse struct {
	ID      string
	Choices []ChatCompletionChoice
	Usage   Usage
}

// ChatCompletionChoice å…¼å®¹æ—§çš„é€‰æ‹©æ ¼å¼
type ChatCompletionChoice struct {
	Message      ChatCompletionMessage
	FinishReason string
}

// Usage å…¼å®¹æ—§çš„ç”¨é‡ç»Ÿè®¡
type Usage struct {
	PromptTokens     int
	CompletionTokens int
	TotalTokens      int
}

// æå–è¯­è¨€æ£€æµ‹è¾…åŠ©æ–¹æ³•
type LanguageContext struct {
	IsEnglish bool
	MainText  string
}

// ä»¥ä¸‹æ˜¯ä¸ºå„ç§æœåŠ¡å®šä¹‰çš„ç»“æ„åŒ–è¾“å‡ºç±»å‹-------------------
// CharacterInfo è§’è‰²ä¿¡æ¯
type CharacterInfo struct {
	Name          string            `json:"name"`
	Role          string            `json:"role"`
	Description   string            `json:"description"`
	Personality   string            `json:"personality"`
	Background    string            `json:"background"`
	SpeechStyle   string            `json:"speech_style"`
	Relationships map[string]string `json:"relationships"`
	Knowledge     []string          `json:"knowledge"`
}

// SceneInfo åœºæ™¯ä¿¡æ¯
type SceneInfo struct {
	Name        string   `json:"name"`
	Description string   `json:"description"`
	Atmosphere  string   `json:"atmosphere"`
	Era         string   `json:"era"`
	Themes      []string `json:"themes"`
	Items       []string `json:"items"`
	Importance  string   `json:"importance"`
}

// ExplorationResult æ¢ç´¢ç»“æœ
type ExplorationResult struct {
	DiscoveredItem *struct {
		Name        string `json:"name"`
		Description string `json:"description"`
		Type        string `json:"type"`
	} `json:"discovered_item,omitempty"`
	StoryEvent *struct {
		Content string `json:"content"`
		Type    string `json:"type"`
		Choices []struct {
			Text        string `json:"text"`
			Consequence string `json:"consequence"`
		} `json:"choices,omitempty"`
	} `json:"story_event,omitempty"`
	NewClue string `json:"new_clue,omitempty"`
}

// -----------------------------------------
// NewLLMService åˆ›å»ºä¸€ä¸ªæ–°çš„LLMæœåŠ¡
func NewLLMService() (*LLMService, error) {
	service := createBaseLLMService()

	// å°è¯•ä»é…ç½®åˆå§‹åŒ–
	cfg := config.GetCurrentConfig()
	if cfg == nil {
		service.readyState = "æ— æ³•è·å–é…ç½®"
		return service, nil
	}

	if cfg.LLMProvider == "" || (cfg.LLMConfig != nil && cfg.LLMConfig["api_key"] == "") {
		service.readyState = "æœªé…ç½®APIå¯†é’¥"
		return service, nil
	}

	// å°è¯•åˆå§‹åŒ–æä¾›å•†
	provider, err := llm.GetProvider(cfg.LLMProvider, cfg.LLMConfig)
	if err != nil {
		service.readyState = fmt.Sprintf("åˆå§‹åŒ–å¤±è´¥: %v", err)
		return service, nil // è¿”å›æœªå°±ç»ªæœåŠ¡è€Œä¸æ˜¯é”™è¯¯
	}

	// åˆå§‹åŒ–æˆåŠŸ
	service.provider = provider
	service.providerName = cfg.LLMProvider
	service.isReady = true
	service.readyState = "å·²å°±ç»ª"

	return service, nil
}

// NewEmptyLLMService åˆ›å»ºä¸€ä¸ªç©ºçš„LLMæœåŠ¡å®ä¾‹ä½œä¸ºåå¤‡æ–¹æ¡ˆ
func NewEmptyLLMService() *LLMService {
	service := createBaseLLMService()
	service.providerName = "empty"
	service.readyState = "åå¤‡æœåŠ¡æ¨¡å¼ - è¯·åœ¨è®¾ç½®ä¸­é…ç½®APIå¯†é’¥"
	return service
}

// createBaseLLMService åˆ›å»ºåŸºç¡€LLMæœåŠ¡å®ä¾‹
func createBaseLLMService() *LLMService {
	return &LLMService{
		provider:     nil,
		providerName: "",
		isReady:      false,
		readyState:   "æœªåˆå§‹åŒ–",
		cache: &LLMCache{
			cache:      make(map[string]*CacheEntry),
			mutex:      sync.RWMutex{},
			expiration: 30 * time.Minute,
		},
	}
}

// IsReady è¿”å›æœåŠ¡æ˜¯å¦å·²å°±ç»ª
func (s *LLMService) IsReady() bool {
	s.providerMutex.RLock()
	defer s.providerMutex.RUnlock()
	return s.isReady
}

// GetReadyState è¿”å›æœåŠ¡å°±ç»ªçŠ¶æ€æè¿°
func (s *LLMService) GetReadyState() string {
	s.providerMutex.RLock()
	defer s.providerMutex.RUnlock()
	return s.readyState
}

// UpdateProvider æ›´æ–°LLMæœåŠ¡çš„æä¾›å•†
func (s *LLMService) UpdateProvider(providerName string, config map[string]string) error {
	provider, err := llm.GetProvider(providerName, config)
	if err != nil {
		s.providerMutex.Lock()
		s.isReady = false
		s.readyState = fmt.Sprintf("é…ç½®å¤±è´¥: %v", err)
		s.providerMutex.Unlock()
		return err
	}

	s.providerMutex.Lock()
	defer s.providerMutex.Unlock()

	s.provider = provider
	s.providerName = providerName
	s.isReady = true
	s.readyState = "å·²å°±ç»ª"

	// æ¸…ç†ç¼“å­˜
	s.cache = &LLMCache{
		cache:      make(map[string]*CacheEntry),
		mutex:      sync.RWMutex{},
		expiration: 30 * time.Minute,
	}

	return nil
}

// generateCacheKey ç”Ÿæˆç¼“å­˜é”®
func (s *LLMService) generateCacheKey(prompt, systemPrompt, model string) string {
	s.providerMutex.RLock()
	providerName := s.providerName
	s.providerMutex.RUnlock()

	hashInput := fmt.Sprintf("%s:::%s:::%s:::%s",
		prompt, systemPrompt, model, providerName)
	h := md5.New()
	h.Write([]byte(hashInput))
	return fmt.Sprintf("%x", h.Sum(nil))
}

// getFromCache ä»ç¼“å­˜ä¸­è·å–ç»“æœ
func (c *LLMCache) getFromCache(key string) (interface{}, bool) {
	c.mutex.RLock()
	defer c.mutex.RUnlock()

	entry, exists := c.cache[key]
	if !exists {
		return nil, false
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Since(entry.CreatedAt) > c.expiration {
		return nil, false
	}

	return entry.Response, true
}

// saveToCache ä¿å­˜ç»“æœåˆ°ç¼“å­˜
func (c *LLMCache) saveToCache(key string, response interface{}) {
	c.mutex.Lock()
	defer c.mutex.Unlock()

	c.cache[key] = &CacheEntry{
		Response:  response,
		CreatedAt: time.Now(),
	}

	// å¦‚æœç¼“å­˜å¤ªå¤§ï¼Œå¯ä»¥è€ƒè™‘æ¸…ç†æœ€æ—§çš„æ¡ç›®
	if len(c.cache) > 1000 {
		c.cleanupOldest(100) // æ¸…ç†100ä¸ªæœ€æ—§çš„æ¡ç›®
	}
}

// cleanupOldest æ¸…ç†æœ€æ—§çš„ç¼“å­˜æ¡ç›®
func (c *LLMCache) cleanupOldest(count int) {
	type keyAge struct {
		key string
		age time.Time
	}

	entries := make([]keyAge, 0, len(c.cache))
	for k, v := range c.cache {
		entries = append(entries, keyAge{k, v.CreatedAt})
	}

	// æŒ‰åˆ›å»ºæ—¶é—´æ’åº
	sort.Slice(entries, func(i, j int) bool {
		return entries[i].age.Before(entries[j].age)
	})

	// åˆ é™¤æœ€æ—§çš„æ¡ç›®
	maxToDelete := min(count, len(entries))
	for i := 0; i < maxToDelete; i++ {
		delete(c.cache, entries[i].key)
	}
}

// å…¼å®¹æ—§çš„CreateChatCompletionæ–¹æ³•
func (s *LLMService) CreateChatCompletion(ctx context.Context, request ChatCompletionRequest) (ChatCompletionResponse, error) {
	// æ„å»ºç³»ç»Ÿå’Œç”¨æˆ·æç¤º
	var systemContent, userContent string
	var assistantMessages []string
	for _, msg := range request.Messages {
		switch msg.Role {
		case RoleSystem:
			systemContent = msg.Content
		case RoleUser:
			userContent = msg.Content
		case RoleAssistant:
			assistantMessages = append(assistantMessages, msg.Content)
		default:
			log.Printf("è­¦å‘Š: æœªçŸ¥çš„æ¶ˆæ¯è§’è‰²ç±»å‹: %s", msg.Role)
		}
	}

	// åŠ©æ‰‹æ¶ˆæ¯å†å²ï¼Œå°†å…¶æ•´åˆåˆ°ç”¨æˆ·æç¤ºä¸­
	if len(assistantMessages) > 0 {
		conversationHistory := strings.Join(assistantMessages, "\n\n")
		userContent = fmt.Sprintf("å¯¹è¯å†å²:\n%s\n\nå½“å‰ç”¨æˆ·è¾“å…¥: %s",
			conversationHistory, userContent)
	}

	// ç”Ÿæˆç¼“å­˜é”®
	cacheKey := s.generateCacheKey(userContent, systemContent, request.Model)

	// æ£€æŸ¥ç¼“å­˜
	if s.cache != nil {
		var cachedResult ChatCompletionResponse
		if s.checkAndUseCache(cacheKey, &cachedResult) {
			log.Printf("DEBUG:LLMèŠå¤©ç¼“å­˜å‘½ä¸­: %s", cacheKey[:8])
			return cachedResult, nil
		}
	}

	// è½¬æ¢è¯·æ±‚æ ¼å¼
	req := llm.CompletionRequest{
		Model:       request.Model,
		Temperature: float32(request.Temperature),
		MaxTokens:   request.MaxTokens,
	}

	req.SystemPrompt = systemContent
	req.Prompt = userContent

	// è°ƒç”¨å®é™…Provider
	resp, err := s.provider.CompleteText(ctx, req)
	if err != nil {
		return ChatCompletionResponse{}, err
	}

	// è½¬æ¢ä¸ºæ—§æ ¼å¼çš„å“åº”
	result := ChatCompletionResponse{
		ID: resp.ModelName + "-" + s.providerName,
		Choices: []ChatCompletionChoice{
			{
				Message: ChatCompletionMessage{
					Role:    "assistant",
					Content: resp.Text,
				},
				FinishReason: resp.FinishReason,
			},
		},
		Usage: Usage{
			PromptTokens:     resp.PromptTokens,
			CompletionTokens: resp.OutputTokens,
			TotalTokens:      resp.TokensUsed,
		},
	}

	// ä¿å­˜åˆ°ç¼“å­˜
	if s.cache != nil {
		s.saveToCache(cacheKey, result)
		log.Printf("DEBUG:ä¿å­˜åˆ°LLMèŠå¤©ç¼“å­˜: %s", cacheKey[:8])
	}

	return result, nil
}

// å¢å¼ºç‰ˆChatCompletion: æ”¯æŒç»“æ„åŒ–è¾“å‡º
// ğŸ”§ ä¼˜åŒ–åçš„ CreateStructuredCompletion
func (s *LLMService) CreateStructuredCompletion(ctx context.Context, prompt string, systemPrompt string, outputSchema interface{}) error {
	// è·å–é»˜è®¤æ¨¡å‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
	s.providerMutex.RLock()
	if !s.isReady || s.provider == nil {
		s.providerMutex.RUnlock()
		return fmt.Errorf("LLMæœåŠ¡æœªå°±ç»ª: %s", s.readyState)
	}

	models := s.provider.GetSupportedModels()
	model := "gpt-4o" // é»˜è®¤å…œåº•å€¼
	if len(models) > 0 {
		model = models[0]
	}
	provider := s.provider
	s.providerMutex.RUnlock()

	// ç”Ÿæˆç¼“å­˜é”®
	cacheKey := s.generateCacheKey(prompt, systemPrompt, model)

	// æ£€æŸ¥ç¼“å­˜
	if s.checkAndUseCache(cacheKey, outputSchema) {
		return nil
	}

	// ä¿®æ”¹ç³»ç»Ÿæç¤ºä»¥è¯·æ±‚ç‰¹å®šæ ¼å¼
	structuredSystemPrompt := systemPrompt
	if systemPrompt != "" {
		structuredSystemPrompt += "\n\n"
	}
	structuredSystemPrompt += "ä»¥æœ‰æ•ˆçš„JSONæ ¼å¼è¿”å›æ‚¨çš„å“åº”ï¼Œéµå¾ªæä¾›çš„è¾“å‡ºæ¶æ„ï¼Œä¸è¦æ·»åŠ è§£é‡Šæˆ–å‰è¨€ã€‚"

	req := llm.CompletionRequest{
		Prompt:       prompt,
		SystemPrompt: structuredSystemPrompt,
		Temperature:  0.3,
		Model:        model,
	}

	// è°ƒç”¨å®é™…Provider
	resp, err := provider.CompleteText(ctx, req)
	if err != nil {
		return err
	}

	// å°è¯•è§£æç»“æ„åŒ–è¾“å‡º
	text := cleanJSONString(resp.Text)

	// è§£æJSONåˆ°æä¾›çš„ç»“æ„ä¸­
	err = json.Unmarshal([]byte(text), outputSchema)
	if err != nil {
		return fmt.Errorf("è§£æAIå“åº”ä¸ºç»“æ„åŒ–æ•°æ®å¤±è´¥: %w\nAIè¿”å›: %s", err, text)
	}

	// ä¿å­˜åˆ°ç¼“å­˜
	s.saveToCache(cacheKey, outputSchema)

	return nil
}

// æ¸…ç†JSONå­—ç¬¦ä¸²ï¼Œå»é™¤å‰åéJSONå†…å®¹
func cleanJSONString(s string) string {
	// æŸ¥æ‰¾ç¬¬ä¸€ä¸ª{
	start := strings.Index(s, "{")
	if start == -1 {
		start = strings.Index(s, "[")
		if start == -1 {
			return s // æ²¡æœ‰æ‰¾åˆ°JSONå¼€å§‹æ ‡è®°
		}
	}

	// æŸ¥æ‰¾æœ€åä¸€ä¸ª}
	end := strings.LastIndex(s, "}")
	if end == -1 {
		end = strings.LastIndex(s, "]")
		if end == -1 {
			return s // æ²¡æœ‰æ‰¾åˆ°JSONç»“æŸæ ‡è®°
		}
		end++
	} else {
		end++
	}

	// æå–JSONéƒ¨åˆ†
	if start < end {
		return s[start:end]
	}
	return s
}

// GenerateScenarioIdeas æ ¹æ®åˆå§‹æ¦‚å¿µç”Ÿæˆåœºæ™¯åˆ›æ„
func (s *LLMService) GenerateScenarioIdeas(ctx context.Context, concept string, genre string, complexity string) (*ScenarioIdeas, error) {
	result := &ScenarioIdeas{}

	// æ£€æµ‹è¾“å…¥æ˜¯å¦ä¸»è¦æ˜¯è‹±æ–‡
	isEnglish := isEnglishText(concept) || isEnglishText(genre)

	var systemPrompt, prompt string

	if isEnglish {
		// âœ… ä¼˜åŒ–åçš„è‹±æ–‡æç¤ºè¯
		systemPrompt = `You are a creative story concept specialist and world-building expert, skilled at crafting compelling, immersive scenarios for interactive stories and games.
Your scenarios should balance originality with player accessibility, offering multiple narrative paths and meaningful choices that reflect the intended genre and complexity level.`

		prompt = fmt.Sprintf(`Generate diverse scenario ideas for an interactive game or story based on the following parameters:

Concept: %s
Genre: %s
Complexity: %s

Create several distinct scenario concepts, each including:
1. Core premise and unique selling proposition
2. Primary character archetypes and their motivations
3. Central conflicts and tension sources
4. Key branching decision points that affect story outcomes
5. Atmospheric elements that reinforce the genre
6. Scalable complexity appropriate to the specified level
7. Potential for player agency and meaningful choices

Ensure each scenario offers rich possibilities for character development, plot progression, and player engagement while staying true to the specified genre conventions.`,
			concept, genre, complexity)
	} else {
		// âœ… ä¼˜åŒ–åçš„ä¸­æ–‡æç¤ºè¯
		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªåˆ›æ„æ•…äº‹æ„æ€ä¸“å®¶å’Œä¸–ç•Œæ„å»ºä¸“å®¶ï¼Œæ“…é•¿ä¸ºäº¤äº’å¼æ•…äº‹å’Œæ¸¸æˆåˆ›é€ å¼•äººå…¥èƒœã€æ²‰æµ¸æ„Ÿå¼ºçš„åœºæ™¯ã€‚
ä½ çš„åœºæ™¯åº”è¯¥å¹³è¡¡åŸåˆ›æ€§ä¸ç©å®¶å¯æ¥å—æ€§ï¼Œæä¾›å¤šæ¡å™äº‹è·¯å¾„å’Œåæ˜ é¢„æœŸç±»å‹å’Œå¤æ‚åº¦çš„æœ‰æ„ä¹‰é€‰æ‹©ã€‚`

		prompt = fmt.Sprintf(`åŸºäºä»¥ä¸‹å‚æ•°ä¸ºäº¤äº’å¼æ¸¸æˆæˆ–æ•…äº‹ç”Ÿæˆå¤šæ ·åŒ–çš„åœºæ™¯åˆ›æ„:

æ¦‚å¿µ: %s
ç±»å‹: %s
å¤æ‚åº¦: %s

åˆ›é€ å‡ ä¸ªä¸åŒçš„åœºæ™¯æ¦‚å¿µï¼Œæ¯ä¸ªåŒ…æ‹¬ï¼š
1. æ ¸å¿ƒå‰æå’Œç‹¬ç‰¹å–ç‚¹
2. ä¸»è¦è§’è‰²åŸå‹åŠå…¶åŠ¨æœºé©±åŠ¨
3. ä¸­å¿ƒå†²çªå’Œå¼ åŠ›æ¥æº
4. å½±å“æ•…äº‹ç»“å±€çš„å…³é”®åˆ†æ”¯å†³ç­–ç‚¹
5. å¼ºåŒ–ç±»å‹ç‰¹è‰²çš„æ°›å›´è¦ç´ 
6. é€‚åº”æŒ‡å®šæ°´å¹³çš„å¯æ‰©å±•å¤æ‚æ€§
7. ç©å®¶èƒ½åŠ¨æ€§å’Œæœ‰æ„ä¹‰é€‰æ‹©çš„æ½œåŠ›

ç¡®ä¿æ¯ä¸ªåœºæ™¯éƒ½ä¸ºè§’è‰²å‘å±•ã€æƒ…èŠ‚æ¨è¿›å’Œç©å®¶å‚ä¸æä¾›ä¸°å¯Œå¯èƒ½æ€§ï¼ŒåŒæ—¶å¿ äºæŒ‡å®šç±»å‹çš„æƒ¯ä¾‹ã€‚`,
			concept, genre, complexity)
	}

	err := s.CreateStructuredCompletion(ctx, prompt, systemPrompt, result)
	if err != nil {
		return nil, err
	}

	return result, nil
}

// AnalyzeLocationContext åˆ†æåœºæ™¯ä¸­çš„ä½ç½®å…³ç³»
func (s *LLMService) AnalyzeLocationContext(ctx context.Context, sceneName string, locations []LocationInfo) (*LocationAnalysis, error) {
	result := &LocationAnalysis{}

	// å°†ä½ç½®ä¿¡æ¯è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
	locationsJSON, err := json.Marshal(locations)
	if err != nil {
		return nil, err
	}

	// æ£€æµ‹è¯­è¨€
	isEnglish := isEnglishText(sceneName)

	// å¦‚æœåœºæ™¯åç§°æ£€æµ‹ä¸ç¡®å®šï¼Œå°è¯•ä»ä½ç½®æè¿°ä¸­æ£€æµ‹
	if !isEnglish && len(locations) > 0 {
		// åˆå¹¶æ‰€æœ‰ä½ç½®åç§°å’Œæè¿°ç”¨äºè¯­è¨€æ£€æµ‹
		var locationTexts []string
		for _, loc := range locations {
			if loc.Name != "" {
				locationTexts = append(locationTexts, loc.Name)
			}
			if loc.Description != "" {
				locationTexts = append(locationTexts, loc.Description)
			}
		}

		combinedText := strings.Join(locationTexts, " ")
		if combinedText != "" {
			isEnglish = isEnglishText(combinedText)
		}
	}

	var systemPrompt, prompt string

	if isEnglish {
		// è‹±æ–‡æç¤ºè¯
		systemPrompt = `You are a spatial planning and story world building expert. Analyze the provided location information, infer spatial relationships between them, possible paths, and story potential.`

		prompt = fmt.Sprintf(`Analyze the following location information in the scene "%s":

%s

Please analyze:
1. Spatial relationships between locations and possible paths
2. Story function and importance of each location
3. Suggested exploration routes
4. Story flow and pacing recommendations`, sceneName, string(locationsJSON))
	} else {
		// ä¸­æ–‡æç¤ºè¯
		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªç©ºé—´è§„åˆ’å’Œæ•…äº‹ä¸–ç•Œæ„å»ºä¸“å®¶ã€‚åˆ†ææä¾›çš„ä½ç½®ä¿¡æ¯ï¼Œæ¨æ–­å®ƒä»¬ä¹‹é—´çš„ç©ºé—´å…³ç³»ã€å¯èƒ½çš„è·¯å¾„å’Œæ•…äº‹æ½œåŠ›ã€‚`

		prompt = fmt.Sprintf(`åˆ†æä»¥ä¸‹åœºæ™¯"%s"ä¸­çš„ä½ç½®ä¿¡æ¯:

%s

è¯·åˆ†æ:
1. ä½ç½®ä¹‹é—´çš„ç©ºé—´å…³ç³»å’Œå¯èƒ½çš„è·¯å¾„
2. æ¯ä¸ªä½ç½®çš„æ•…äº‹åŠŸèƒ½å’Œé‡è¦æ€§
3. å¯èƒ½çš„æ¢ç´¢è·¯çº¿å»ºè®®
4. æ•…äº‹æµåŠ¨å’ŒèŠ‚å¥å»ºè®®`, sceneName, string(locationsJSON))
	}

	err = s.CreateStructuredCompletion(ctx, prompt, systemPrompt, result)
	if err != nil {
		return nil, err
	}

	return result, nil
}

// GenerateCharacterInteraction ç”Ÿæˆè§’è‰²äº’åŠ¨å†…å®¹
func (s *LLMService) GenerateCharacterInteraction(ctx context.Context, character1 CharacterInfo, character2 CharacterInfo, situation string) (*CharacterInteraction, error) {
	result := &CharacterInteraction{}

	// å°†è§’è‰²ä¿¡æ¯è½¬æ¢ä¸ºJSON
	char1JSON, _ := json.Marshal(character1)
	char2JSON, _ := json.Marshal(character2)

	// æ£€æµ‹è¾“å…¥è¯­è¨€
	isEnglish := isEnglishText(character1.Name + " " + character2.Name + " " + situation)

	var systemPrompt, prompt string

	if isEnglish {
		// è‹±æ–‡æç¤ºè¯
		systemPrompt = `You are a dialogue and character interaction expert. Based on the provided character information and situation, create authentic, engaging interactions that match character traits.
Ensure the dialogue reflects each character's personality, speech style, and motivations.`

		prompt = fmt.Sprintf(`Create an interaction between the following two characters in the given situation:

Character 1: %s

Character 2: %s

Situation: %s

Generate a dialogue sequence with the following requirements:
1. Each character's dialogue should reflect their unique personality traits and speech patterns
2. The interaction should advance the plot or reveal character development
3. Include appropriate emotional expressions and subtle body language descriptions
4. Limit the conversation to 3-5 exchanges between characters
5. Ensure the dialogue maintains logical consistency with the given situation
6. Consider the relationship dynamics between the characters
7. If conflict arises, show how each character would realistically respond

Format the output to show clear speaker attribution and any relevant actions or emotional states.`, string(char1JSON), string(char2JSON), situation)
	} else {
		// ä¸­æ–‡æç¤ºè¯ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªå¯¹è¯å’Œè§’è‰²äº’åŠ¨ä¸“å®¶ã€‚æ ¹æ®æä¾›çš„è§’è‰²ä¿¡æ¯å’Œæƒ…å¢ƒï¼Œåˆ›é€ çœŸå®ã€æœ‰è¶£ä¸”ç¬¦åˆè§’è‰²ç‰¹ç‚¹çš„äº’åŠ¨ã€‚
ç¡®ä¿å¯¹è¯åæ˜ è§’è‰²çš„æ€§æ ¼ã€è¯´è¯é£æ ¼å’ŒåŠ¨æœºã€‚`

		prompt = fmt.Sprintf(`åˆ›å»ºä»¥ä¸‹ä¸¤ä¸ªè§’è‰²åœ¨ç»™å®šæƒ…å¢ƒä¸‹çš„äº’åŠ¨:

è§’è‰²1: %s

è§’è‰²2: %s

æƒ…å¢ƒ: %s

è¯·ç”Ÿæˆä¸€æ®µå¯¹è¯åºåˆ—ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š
1. æ¯ä¸ªè§’è‰²çš„å¯¹è¯åº”ä½“ç°å…¶ç‹¬ç‰¹çš„æ€§æ ¼ç‰¹å¾å’Œè¯´è¯æ–¹å¼
2. äº’åŠ¨åº”æ¨è¿›æƒ…èŠ‚å‘å±•æˆ–æ­ç¤ºè§’è‰²æˆé•¿
3. åŒ…å«é€‚å½“çš„æƒ…ç»ªè¡¨è¾¾å’Œç»†å¾®çš„è‚¢ä½“è¯­è¨€æè¿°
4. è§’è‰²é—´çš„å¯¹è¯äº¤æµé™åˆ¶åœ¨3-5è½®ä»¥å†…
5. ç¡®ä¿å¯¹è¯ä¸ç»™å®šæƒ…å¢ƒä¿æŒé€»è¾‘ä¸€è‡´æ€§
6. è€ƒè™‘è§’è‰²ä¹‹é—´çš„å…³ç³»åŠ¨æ€
7. å¦‚æœå‡ºç°å†²çªï¼Œå±•ç¤ºæ¯ä¸ªè§’è‰²ä¼šå¦‚ä½•çœŸå®åœ°å›åº”

è¾“å‡ºæ ¼å¼è¦æ˜¾ç¤ºæ¸…æ™°çš„è¯´è¯è€…å½’å±å’Œä»»ä½•ç›¸å…³çš„åŠ¨ä½œæˆ–æƒ…ç»ªçŠ¶æ€ã€‚`, string(char1JSON), string(char2JSON), situation)
	}

	err := s.CreateStructuredCompletion(ctx, prompt, systemPrompt, result)
	if err != nil {
		return nil, err
	}

	return result, nil
}

// GetProvider è¿”å›å†…éƒ¨çš„Providerå®ä¾‹
func (s *LLMService) GetProvider() llm.Provider {
	s.providerMutex.RLock()
	defer s.providerMutex.RUnlock()
	return s.provider
}

// GetProviderName è¿”å›å½“å‰LLMæä¾›å•†åç§°
func (s *LLMService) GetProviderName() string {
	s.providerMutex.RLock()
	defer s.providerMutex.RUnlock()
	return s.providerName
}

// isEnglishText æ£€æµ‹æ–‡æœ¬æ˜¯å¦ä¸ºè‹±æ–‡
func isEnglishText(text string) bool {
	if len(text) == 0 {
		return false
	}

	// è®¡æ•°
	letterCount := 0
	chineseCount := 0
	totalValidChars := 0 // æœ‰æ•ˆå­—ç¬¦æ€»æ•°

	for _, r := range text {
		// è‹±æ–‡å­—æ¯
		if (r >= 'a' && r <= 'z') || (r >= 'A' && r <= 'Z') {
			letterCount++
			totalValidChars++
		}
		// æ£€æµ‹ä¸­æ–‡å­—ç¬¦
		if r >= 0x4E00 && r <= 0x9FFF {
			chineseCount++
			totalValidChars++
		}
		// æ•°å­—ä¹Ÿç®—æœ‰æ•ˆå­—ç¬¦
		if r >= '0' && r <= '9' {
			totalValidChars++
		}
	}

	// åˆ¤å®šè§„åˆ™ï¼š
	// 1. å¦‚æœæ²¡æœ‰æœ‰æ•ˆå­—ç¬¦ï¼Œè¿”å› false
	if totalValidChars == 0 {
		return false
	}

	// 2. è®¡ç®—è‹±æ–‡å­—æ¯å æœ‰æ•ˆå­—ç¬¦çš„æ¯”ä¾‹
	englishRatio := float64(letterCount) / float64(totalValidChars)

	// 3. å¦‚æœè‹±æ–‡å­—æ¯æ¯”ä¾‹è¶…è¿‡50%ï¼Œè®¤ä¸ºæ˜¯è‹±æ–‡æ–‡æœ¬
	// è¿™æ · "Mixed ä¸­è‹±æ–‡" ä¸­çš„ "Mixed" å ä¸»å¯¼ï¼Œä¼šè¢«åˆ¤å®šä¸ºè‹±æ–‡
	return englishRatio > 0.5
}

// ç”¨äºç»“æ„åŒ–è¾“å‡ºæ—¶æŠ½å–è§’è‰²ä¿¡æ¯
func (s *LLMService) ExtractCharacters(ctx context.Context, text, title string) ([]CharacterInfo, error) {
	// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return nil, ctx.Err()
	default:
		// ç»§ç»­æ‰§è¡Œ
	}

	// æ£€æµ‹æ–‡æœ¬è¯­è¨€
	isEnglish := isEnglishText(text)

	var prompt, systemPrompt string
	if isEnglish {
		// è‹±æ–‡æç¤ºè¯
		prompt = fmt.Sprintf(`Analyze the following text titled "%s" and extract all character information:

%s

Identify all possible characters from the text, including names, personality traits, appearance descriptions, etc. For each character, provide as detailed information as possible.`, title, text)

		systemPrompt = `You are a professional literary character analyst, skilled at extracting character information from texts. Extract all characters that appear in the text, including both main and supporting characters.`
	} else {
		// ä¸­æ–‡æç¤ºè¯ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
		prompt = fmt.Sprintf(`åˆ†æä»¥ä¸‹æ ‡é¢˜ä¸ºã€Š%sã€‹çš„æ–‡æœ¬ï¼Œæå–æ‰€æœ‰è§’è‰²ä¿¡æ¯:

%s

ä»æ–‡æœ¬ä¸­è¯†åˆ«æ‰€æœ‰å¯èƒ½çš„è§’è‰²ï¼ŒåŒ…æ‹¬åå­—ã€æ€§æ ¼ç‰¹ç‚¹ã€å¤–è¡¨æè¿°ç­‰ã€‚å¯¹äºæ¯ä¸ªè§’è‰²ï¼Œæä¾›å°½å¯èƒ½è¯¦ç»†çš„ä¿¡æ¯ã€‚`, title, text)

		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡å­¦è§’è‰²åˆ†æä¸“å®¶ï¼Œæ“…é•¿æå–æ–‡æœ¬ä¸­çš„äººç‰©ä¿¡æ¯ã€‚æå–æ–‡æœ¬ä¸­å‡ºç°çš„æ‰€æœ‰è§’è‰²ï¼ŒåŒ…æ‹¬ä¸»è¦å’Œæ¬¡è¦è§’è‰²ã€‚`
	}

	// ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºAPI
	request := llm.CompletionRequest{
		Model:        s.GetDefaultModel(),
		Prompt:       prompt,
		SystemPrompt: systemPrompt,
		MaxTokens:    2000,
		Temperature:  0.2,
	}

	cacheKey := s.GenerateCacheKey(request)
	if cachedResp := s.CheckCache(cacheKey); cachedResp != nil {
		// å°è¯•è§£æä¸ºæ•°ç»„æ ¼å¼
		var characters []CharacterInfo
		err := json.Unmarshal([]byte(cachedResp.Text), &characters)
		if err == nil {
			return characters, nil
		}

		// å¦‚æœè§£ææ•°ç»„å¤±è´¥ï¼Œå°è¯•è§£æä¸ºå•ä¸ªå¯¹è±¡
		var singleCharacter CharacterInfo
		err = json.Unmarshal([]byte(cachedResp.Text), &singleCharacter)
		if err != nil {
			return nil, fmt.Errorf("è§£æç¼“å­˜çš„AIå“åº”ä¸ºç»“æ„åŒ–æ•°æ®å¤±è´¥: %w\nAIè¿”å›: %s",
				err, truncateText(cachedResp.Text, 120))
		}

		// å°†å•ä¸ªå¯¹è±¡æ·»åŠ åˆ°æ•°ç»„ä¸­
		return []CharacterInfo{singleCharacter}, nil
	}

	response, err := s.provider.CompleteText(ctx, request)
	if err != nil {
		return nil, err
	}
	// æ·»åŠ åˆ°ç¼“å­˜
	s.AddToCache(cacheKey, response)

	// å°è¯•è§£æä¸ºæ•°ç»„æ ¼å¼
	var characters []CharacterInfo
	err = json.Unmarshal([]byte(response.Text), &characters)
	if err == nil {
		return characters, nil
	}

	// å¦‚æœè§£ææ•°ç»„å¤±è´¥ï¼Œå°è¯•è§£æä¸ºå•ä¸ªå¯¹è±¡
	var singleCharacter CharacterInfo
	err = json.Unmarshal([]byte(response.Text), &singleCharacter)
	if err != nil {
		return nil, fmt.Errorf("è§£æAIå“åº”ä¸ºç»“æ„åŒ–æ•°æ®å¤±è´¥: %w\nAIè¿”å›: %s",
			err, truncateText(response.Text, 120))
	}

	// å°†å•ä¸ªå¯¹è±¡æ·»åŠ åˆ°æ•°ç»„ä¸­
	return []CharacterInfo{singleCharacter}, nil
}

// ç”¨äºæå–åœºæ™¯ä¿¡æ¯
func (s *LLMService) ExtractScenes(ctx context.Context, text, title string) ([]SceneInfo, error) {
	// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return nil, ctx.Err()
	default:
		// ç»§ç»­æ‰§è¡Œ
	}

	// æ£€æµ‹æ–‡æœ¬è¯­è¨€
	isEnglish := isEnglishText(text)

	var prompt, systemPrompt string
	if isEnglish {
		prompt = fmt.Sprintf(`Analyze the following text titled "%s" and extract all scene information:

%s

Identify the main scenes in the text, including:
1. Scene name
2. Detailed description
3. Scene atmosphere
4. Time period/era
5. Thematic elements
6. Major items or props present in the scene`,
			title, truncateText(text, 5000))

		systemPrompt = `You are a professional scene analysis expert. Please extract key scene information from the text. Return in JSON format, including scene name, description, atmosphere, era, themes, and a list of items.`
	} else {
		// åŸæœ‰ä¸­æ–‡æç¤ºè¯
		prompt = fmt.Sprintf(`åˆ†æä»¥ä¸‹æ ‡é¢˜ä¸ºã€Š%sã€‹çš„æ–‡æœ¬ï¼Œæå–æ‰€æœ‰åœºæ™¯ä¿¡æ¯:

%s

è¯†åˆ«æ–‡ä¸­çš„ä¸»è¦åœºæ™¯ï¼ŒåŒ…æ‹¬:
1. åœºæ™¯åç§°
2. è¯¦ç»†æè¿°
3. åœºæ™¯æ°›å›´
4. æ—¶ä»£èƒŒæ™¯
5. ä¸»é¢˜å…ƒç´ 
6. åœºæ™¯ä¸­å‡ºç°çš„ä¸»è¦ç‰©å“`,
			title, truncateText(text, 5000))

		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœºæ™¯åˆ†æä¸“å®¶ï¼Œè¯·ä»æ–‡æœ¬ä¸­æå–å…³é”®åœºæ™¯ä¿¡æ¯ã€‚è¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«åœºæ™¯åç§°(name)ã€æè¿°(description)ã€æ°›å›´(atmosphere)ã€æ—¶ä»£èƒŒæ™¯(era)ã€ä¸»é¢˜(themes)å’Œç‰©å“åˆ—è¡¨(items)ã€‚`
	}

	// ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºAPI
	request := llm.CompletionRequest{
		Model:        s.GetDefaultModel(),
		Prompt:       prompt,
		SystemPrompt: systemPrompt,
		MaxTokens:    2000,
		Temperature:  0.2,
	}

	cacheKey := s.GenerateCacheKey(request)
	if cachedResp := s.CheckCache(cacheKey); cachedResp != nil {
		// å°è¯•è§£æä¸ºæ•°ç»„æ ¼å¼
		var scenes []SceneInfo
		err := json.Unmarshal([]byte(cachedResp.Text), &scenes)
		if err == nil {
			return scenes, nil
		}

		// å¦‚æœè§£ææ•°ç»„å¤±è´¥ï¼Œå°è¯•è§£æä¸ºå•ä¸ªå¯¹è±¡
		var singleScene SceneInfo
		err = json.Unmarshal([]byte(cachedResp.Text), &singleScene)
		if err != nil {
			return nil, fmt.Errorf("è§£æç¼“å­˜çš„AIå“åº”ä¸ºç»“æ„åŒ–æ•°æ®å¤±è´¥: %w\nAIè¿”å›: %s",
				err, truncateText(cachedResp.Text, 120))
		}

		// å°†å•ä¸ªå¯¹è±¡æ·»åŠ åˆ°æ•°ç»„ä¸­
		return []SceneInfo{singleScene}, nil
	}

	response, err := s.provider.CompleteText(ctx, request)
	if err != nil {
		return nil, err
	}
	// æ·»åŠ åˆ°ç¼“å­˜
	s.AddToCache(cacheKey, response)

	// å°è¯•è§£æä¸ºæ•°ç»„æ ¼å¼
	var scenes []SceneInfo
	err = json.Unmarshal([]byte(response.Text), &scenes)
	if err == nil {
		return scenes, nil
	}

	// å¦‚æœè§£ææ•°ç»„å¤±è´¥ï¼Œå°è¯•è§£æä¸ºå•ä¸ªå¯¹è±¡
	var singleScene SceneInfo
	err = json.Unmarshal([]byte(response.Text), &singleScene)
	if err != nil {
		return nil, fmt.Errorf("è§£æAIå“åº”ä¸ºç»“æ„åŒ–æ•°æ®å¤±è´¥: %w\nAIè¿”å›: %s",
			err, truncateText(response.Text, 120))
	}

	// å°†å•ä¸ªå¯¹è±¡æ·»åŠ åˆ°æ•°ç»„ä¸­
	return []SceneInfo{singleScene}, nil
}

// GenerateCacheKey ä¸ºè¯·æ±‚ç”Ÿæˆç¼“å­˜é”®
func (s *LLMService) GenerateCacheKey(req llm.CompletionRequest) string {
	return s.generateCacheKey(req.Prompt, req.SystemPrompt, req.Model)
}

// CheckCache æ£€æŸ¥å¹¶è¿”å›ç¼“å­˜çš„å“åº”
func (s *LLMService) CheckCache(key string) *llm.CompletionResponse {
	if s.cache == nil {
		return nil
	}

	if entry, found := s.cache.getFromCache(key); found {
		if response, ok := entry.(*llm.CompletionResponse); ok {
			return response
		}
	}
	return nil
}

// AddToCache æ·»åŠ å“åº”åˆ°ç¼“å­˜
func (s *LLMService) AddToCache(key string, response *llm.CompletionResponse) {
	if s.cache != nil {
		s.cache.saveToCache(key, response)
	}
}

// AnalyzeContent åˆ†ææ–‡æœ¬å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
func (s *LLMService) AnalyzeContent(ctx context.Context, text string) (*ContentAnalysis, error) {
	result := &ContentAnalysis{}

	// æ£€æµ‹æ–‡æœ¬è¯­è¨€
	isEnglish := isEnglishText(text)

	var systemPrompt, prompt string
	if isEnglish {
		systemPrompt = `You are a professional literary analyst who extracts key information from texts, including characters, scenes, important props, and major plot points. Provide detailed and precise analysis, ensuring the result format meets requirements. Do not add explanations or preambles.`

		prompt = fmt.Sprintf(`Please analyze the following text and extract all key information:

%s

Please extract information in the following categories:
1. Characters: All characters that appear, including names, traits, and relationships
2. Scenes: All locations and scenes that appear, including descriptions and atmosphere
3. Props: Important items or props mentioned in the text, including usage methods and effects
4. Plot: Major plot points and events
5. Themes: Core themes or ideas the text may express`, text)
	} else {
		// åŸæœ‰ä¸­æ–‡æç¤ºè¯
		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡å­¦åˆ†æä¸“å®¶ï¼Œéœ€è¦ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬è§’è‰²ã€åœºæ™¯ã€é‡è¦é“å…·å’Œä¸»è¦æƒ…èŠ‚ç‚¹ã€‚
æä¾›è¯¦ç»†è€Œç²¾ç¡®çš„åˆ†æï¼Œç¡®ä¿ç»“æœæ ¼å¼ç¬¦åˆè¦æ±‚ã€‚ä¸è¦æ·»åŠ è§£é‡Šæˆ–å‰è¨€ã€‚`

		prompt = fmt.Sprintf(`è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæå–æ‰€æœ‰å…³é”®ä¿¡æ¯:

%s

è¯·æå–ä»¥ä¸‹ç±»åˆ«çš„ä¿¡æ¯:
1. è§’è‰²: æ‰€æœ‰å‡ºç°çš„è§’è‰²ï¼ŒåŒ…æ‹¬åç§°ã€ç‰¹å¾å’Œå…³ç³»
2. åœºæ™¯: æ‰€æœ‰å‡ºç°çš„åœ°ç‚¹å’Œåœºæ™¯ï¼ŒåŒ…æ‹¬æè¿°å’Œæ°›å›´
3. é“å…·: æ–‡ä¸­æåˆ°çš„é‡è¦ç‰©å“æˆ–é“å…·ï¼Œä»¥åŠä½¿ç”¨æ–¹æ³•ã€æ•ˆæœ
4. æƒ…èŠ‚: ä¸»è¦æƒ…èŠ‚ç‚¹å’Œäº‹ä»¶
5. ä¸»é¢˜: æ–‡æœ¬å¯èƒ½è¡¨è¾¾çš„æ ¸å¿ƒä¸»é¢˜æˆ–æ€æƒ³`, text)
	}

	err := s.CreateStructuredCompletion(ctx, prompt, systemPrompt, result)
	if err != nil {
		return nil, err
	}

	return result, nil
}

// GenerateExplorationResult ç”¨äºæ¢ç´¢åœ°ç‚¹æ—¶çš„ç»“æœåˆ†æ
func (s *LLMService) GenerateExplorationResult(ctx context.Context, sceneName, locationName, locationDesc, sceneDesc, creativityLevel string, allowPlotTwists bool) (*ExplorationResult, error) {
	var result ExplorationResult

	// æ£€æµ‹åœºæ™¯æè¿°è¯­è¨€
	isEnglish := isEnglishText(sceneDesc)

	var prompt, systemPrompt string
	if isEnglish {
		// âœ… ä¼˜åŒ–åçš„è‹±æ–‡æç¤ºè¯
		systemPrompt = `You are a creative story designer and game master specializing in interactive fiction experiences.
Your role is to generate meaningful, contextually appropriate exploration results that enhance player engagement and narrative progression while maintaining consistency with the established world and atmosphere.`

		prompt = fmt.Sprintf(`In the scene "%s", the player is exploring the location "%s".

Location Description: %s
Scene Background: %s
Creativity Level: %s
Allow Plot Twists: %t

Generate exploration results following these guidelines:
1. If creativity level is "high", introduce unexpected discoveries or hidden elements that surprise the player
2. If plot twists are allowed, introduce new story threads, mysteries, or conflicts that deepen the narrative
3. Results must align with the location's characteristics and the overall scene atmosphere
4. Priority hierarchy: Significant story events > Useful items/tools > Background lore/clues
5. Ensure exploration results contribute to overall story progression and player agency
6. Consider environmental storytelling - what would realistically be found in this specific location?
7. Balance immediate rewards with long-term narrative payoffs

Generate 1-2 specific, detailed exploration results that feel organic to the world and situation.`,
			sceneName, locationName, locationDesc, sceneDesc, creativityLevel, allowPlotTwists)
	} else {
		// âœ… ä¼˜åŒ–åçš„ä¸­æ–‡æç¤ºè¯
		systemPrompt = `ä½ æ˜¯ä¸€ä¸ªåˆ›æ„æ•…äº‹è®¾è®¡å¸ˆå’Œæ¸¸æˆä¸»æŒäººï¼Œä¸“é—¨è®¾è®¡äº’åŠ¨å°è¯´ä½“éªŒã€‚
ä½ çš„ä»»åŠ¡æ˜¯ç”Ÿæˆæœ‰æ„ä¹‰ã€ç¬¦åˆæƒ…å¢ƒçš„æ¢ç´¢ç»“æœï¼Œæå‡ç©å®¶å‚ä¸åº¦å’Œå™äº‹æ¨è¿›ï¼ŒåŒæ—¶ä¿æŒä¸æ—¢å®šä¸–ç•Œè§‚å’Œæ°›å›´çš„ä¸€è‡´æ€§ã€‚`

		prompt = fmt.Sprintf(`åœ¨ã€Š%sã€‹è¿™ä¸ªåœºæ™¯ä¸­ï¼Œç©å®¶æ­£åœ¨æ¢ç´¢åœ°ç‚¹"%s"ã€‚

åœ°ç‚¹æè¿°: %s
åœºæ™¯èƒŒæ™¯: %s
åˆ›æ„æ°´å¹³: %s
å…è®¸å‰§æƒ…è½¬æŠ˜: %t

æ ¹æ®ä»¥ä¸‹å‡†åˆ™ç”Ÿæˆæ¢ç´¢ç»“æœï¼š
1. å¦‚æœåˆ›æ„æ°´å¹³ä¸º"é«˜"ï¼Œå¼•å…¥ä»¤ç©å®¶æƒŠå–œçš„æ„å¤–å‘ç°æˆ–éšè—è¦ç´ 
2. å¦‚æœå…è®¸å‰§æƒ…è½¬æŠ˜ï¼Œå¼•å…¥æ·±åŒ–å™äº‹çš„æ–°æ•…äº‹çº¿ç´¢ã€è°œå›¢æˆ–å†²çª
3. ç»“æœå¿…é¡»ä¸åœ°ç‚¹ç‰¹å¾å’Œæ•´ä½“åœºæ™¯æ°›å›´ä¿æŒä¸€è‡´
4. ä¼˜å…ˆçº§å±‚æ¬¡ï¼šé‡è¦æ•…äº‹äº‹ä»¶ > æœ‰ç”¨é“å…·/å·¥å…· > èƒŒæ™¯ä¼ è¯´/çº¿ç´¢
5. ç¡®ä¿æ¢ç´¢ç»“æœèƒ½ä¿ƒè¿›æ•´ä½“æ•…äº‹æ¨è¿›å’Œç©å®¶èƒ½åŠ¨æ€§
6. è€ƒè™‘ç¯å¢ƒå™äº‹â€”â€”åœ¨è¿™ä¸ªç‰¹å®šåœ°ç‚¹ç°å®ä¸­ä¼šå‘ç°ä»€ä¹ˆï¼Ÿ
7. å¹³è¡¡å³æ—¶å¥–åŠ±ä¸é•¿æœŸå™äº‹å›æŠ¥

ç”Ÿæˆ1-2ä¸ªå…·ä½“ã€è¯¦ç»†çš„æ¢ç´¢ç»“æœï¼Œè®©å®ƒä»¬æ„Ÿè§‰æ˜¯è¿™ä¸ªä¸–ç•Œå’Œæƒ…å¢ƒçš„æœ‰æœºç»„æˆéƒ¨åˆ†ã€‚`,
			sceneName, locationName, locationDesc, sceneDesc, creativityLevel, allowPlotTwists)
	}

	// ä½¿ç”¨CreateStructuredCompletion
	err := s.CreateStructuredCompletion(ctx, prompt, systemPrompt, &result)
	if err != nil {
		return nil, err
	}

	return &result, nil
}

// GetDefaultModel è·å–å½“å‰é…ç½®çš„é»˜è®¤æ¨¡å‹
func (s *LLMService) GetDefaultModel() string {
	s.providerMutex.RLock()
	defer s.providerMutex.RUnlock()

	// å¦‚æœLLMæœåŠ¡ä¸å¯ç”¨æˆ–æœªå°±ç»ªï¼Œè¿”å›é»˜è®¤å€¼
	if !s.isReady || s.provider == nil {
		return "gpt-4.1"
	}

	// è·å–æä¾›å•†æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
	models := s.provider.GetSupportedModels()
	if len(models) > 0 {
		return models[0]
	}

	// æ ¹æ®æä¾›å•†åç§°è¿”å›é»˜è®¤æ¨¡å‹
	defaultModels := map[string]string{
		"OpenAI":           "gpt-4.1",
		"Anthropic Claude": "claude-3.5-sonnet",
		"Mistral":          "mistral-large-latest",
		"DeepSeek":         "deepseek-chat",
		"GLM":              "glm-4",
		"google gemini":    "gemini-2.0-flash",
		"Qwen":             "qwen2.5-max",
		"GitHub Models":    "gpt-4.1",
		"Grok":             "grok-3",
		"openrouter":       "google/gemma-3-27b-it:free",
	}

	if model, exists := defaultModels[s.providerName]; exists {
		return model
	}

	return "gpt-4.1" // å…œåº•é»˜è®¤å€¼
}

// ç»Ÿä¸€çš„ç¼“å­˜æ“ä½œæ–¹æ³•
func (s *LLMService) checkAndUseCache(cacheKey string, outputSchema interface{}) bool {
	if s.cache == nil {
		return false
	}

	if cachedResponse, found := s.cache.getFromCache(cacheKey); found {
		// ç›´æ¥å°†ç¼“å­˜å“åº”ä½œä¸º JSON å­—èŠ‚å¤„ç†
		if responseBytes, ok := cachedResponse.([]byte); ok {
			if outputSchema != nil {
				// å°è¯•å°†ç¼“å­˜çš„ JSON å­—èŠ‚ååºåˆ—åŒ–åˆ°è¾“å‡ºç»“æ„
				err := json.Unmarshal(responseBytes, outputSchema)
				if err == nil {
					log.Printf("DEBUG:LLMç¼“å­˜å‘½ä¸­: %s", cacheKey[:8])
					return true
				}
			}
		}
		// å¦‚æœç¼“å­˜é¡¹ä¸æ˜¯å­—èŠ‚åˆ‡ç‰‡ï¼Œåˆ™å°è¯•å…¶ä»–ç±»å‹è½¬æ¢ï¼ˆå‘åå…¼å®¹ï¼‰
		if resp, ok := cachedResponse.(ChatCompletionResponse); ok {
			if outputSchema != nil {
				// å¯¹äºç»“æ„åŒ–è¾“å‡ºï¼Œå°è¯• JSON è½¬æ¢
				responseJSON, err := json.Marshal(resp)
				if err == nil {
					err = json.Unmarshal(responseJSON, outputSchema)
					if err == nil {
						log.Printf("DEBUG:LLMç¼“å­˜å‘½ä¸­: %s", cacheKey[:8])
						return true
					}
				}
			} else {
				// å¯¹äºæ™®é€šå“åº”ï¼Œç›´æ¥è¿”å›
				if chatResp, ok := outputSchema.(*ChatCompletionResponse); ok {
					*chatResp = resp
					log.Printf("DEBUG:LLMç¼“å­˜å‘½ä¸­: %s", cacheKey[:8])
					return true
				}
			}
		}

		// å°è¯•ç›´æ¥è½¬æ¢ä¸º CompletionResponse
		if resp, ok := cachedResponse.(*llm.CompletionResponse); ok {
			if outputSchema != nil {
				err := json.Unmarshal([]byte(resp.Text), outputSchema)
				if err == nil {
					log.Printf("DEBUG:LLMç¼“å­˜å‘½ä¸­: %s", cacheKey[:8])
					return true
				}
			}
		}
	}

	return false
}

// ç»Ÿä¸€çš„ç¼“å­˜ä¿å­˜æ–¹æ³•
func (s *LLMService) saveToCache(cacheKey string, response interface{}) {
	if s.cache != nil {
		// æ€»æ˜¯å°†å“åº”åºåˆ—åŒ–ä¸ºJSONå­—èŠ‚å­˜å‚¨ï¼Œä»¥ç¡®ä¿ä¸€è‡´çš„ç±»å‹å¤„ç†
		responseBytes, err := json.Marshal(response)
		if err != nil {
			log.Printf("ERROR:åºåˆ—åŒ–ç¼“å­˜å“åº”å¤±è´¥: %v", err)
			// ä»ç„¶å°è¯•ä¿å­˜åŸå§‹å“åº”ä»¥å‘åå…¼å®¹
			s.cache.saveToCache(cacheKey, response)
		} else {
			s.cache.saveToCache(cacheKey, responseBytes)
		}
		log.Printf("DEBUG:ä¿å­˜åˆ°LLMç¼“å­˜: %s", cacheKey[:8])
	}
}
